// ë§ˆì´í¬ ì†Œë¦¬ë¥¼ ë°›ì•„ì„œ PCM(Int16)ìœ¼ë¡œ ë³€í™˜í•˜ê³ 
// WebSocketìœ¼ë¡œ ë³´ë‚´ê³  ë””ë²„ê·¸ìš© WAV íŒŒì¼ê¹Œì§€ ë§Œë“¤ì–´ì£¼ëŠ” í›…

import { useCallback, useEffect, useRef, useState } from "react";

// STT ì„œë²„ì—ì„œ ë§ì´ ì‚¬ìš©í•˜ëŠ” í‘œì¤€ ìƒ˜í”Œë ˆì´íŠ¸ (16kHz)
const SAMPLE_RATE = 16000;

export function usePcmStream(wsUrl?: string) {
  // ì‹¤ì œ AudioContextì—ì„œ ì‚¬ìš©í•˜ëŠ” ìƒ˜í”Œë ˆì´íŠ¸ (ë””ë²„ê·¸ìš©)
  const [debugSampleRate, setDebugSampleRate] = useState<number>(SAMPLE_RATE);

  // ë‚´ë¶€ì—ì„œ ê³„ì† ìœ ì§€í•  ê°ì²´ë“¤ (Ref)
  const audioContextRef = useRef<AudioContext | null>(null);
  const sourceRef = useRef<MediaStreamAudioSourceNode | null>(null);
  const processorRef = useRef<ScriptProcessorNode | null>(null);

  // WebSocket ì—°ê²°
  const wsRef = useRef<WebSocket | null>(null);

  // ìŠ¤íŠ¸ë¦¬ë° ì¤‘ì¸ì§€ ì—¬ë¶€ (UI í‘œì‹œìš©)
  const [isStreaming, setIsStreaming] = useState(false);

  // ë””ë²„ê·¸ìš© ìƒíƒœ
  const [chunkCount, setChunkCount] = useState(0);
  const [totalBytes, setTotalBytes] = useState(0);

  // ë””ë²„ê·¸ìš©: ë…¹ìŒëœ PCMì„ ë©”ëª¨ë¦¬ì— ì €ì¥
  const recordedChunksRef = useRef<Int16Array[]>([]);

  // ë””ë²„ê·¸ìš©: stop() í›„ ë¸Œë¼ìš°ì €ì—ì„œ ì¬ìƒí•  WAV URL
  const [debugAudioUrl, setDebugAudioUrl] = useState<string | null>(null);

  const [isWsOpen, setIsWsOpen] = useState(false);

  // âœ… ì¤‘ë³µ stop ë°©ì§€
  const isStoppingRef = useRef(false);

  // âœ… ENDë¥¼ ë°›ì•˜ëŠ”ì§€ / TTS ì¬ìƒ ì¡°ê° ì¹´ìš´íŠ¸
  const endingRef = useRef(false);
  const playingCountRef = useRef(0);

  // âœ… onmessage ì•ˆì—ì„œ stop()ì„ ë¶€ë¥´ê¸° ìœ„í•œ ref (ì„ ì–¸ ìˆœì„œ ë¬¸ì œ í•´ê²°)
  const stopRef = useRef<() => void>(() => {});
//   const requestStop = useCallback(() => stopRef.current(), []);

  // âœ… WS+AudioContextë§Œ ë‹«ëŠ” â€œë§ˆì§€ë§‰ ì¢…ë£Œâ€ (TTS ëê¹Œì§€ ë“£ê³  ë‹«ì„ ë•Œ ì‚¬ìš©)
  const finalClose = useCallback(() => {
    console.log("[usePcmStream] finalClose()");

    // AudioContext ì¢…ë£Œ
    audioContextRef.current?.close();
    audioContextRef.current = null;

    // WebSocket ì¢…ë£Œ
    if (wsRef.current) {
      try {
        wsRef.current.onopen = null;
        wsRef.current.onmessage = null;
        wsRef.current.onerror = null;
        wsRef.current.onclose = null;

        if (
          wsRef.current.readyState === WebSocket.OPEN ||
          wsRef.current.readyState === WebSocket.CONNECTING
        ) {
          wsRef.current.close();
        }
      } catch (e) {
        console.warn("[usePcmStream] finalClose ws close failed", e);
      } finally {
        wsRef.current = null;
      }
    }

    setIsWsOpen(false);
  }, []);

  // âœ… ë§ˆì´í¬ ì†¡ì‹ ë§Œ ë©ˆì¶”ëŠ” í•¨ìˆ˜ (END ì‹œ: â€œë…¹ìŒ ì¤‘ë‹¨â€ + â€œTTSëŠ” ëê¹Œì§€ ìˆ˜ì‹ /ì¬ìƒâ€)
  const stopCaptureOnly = useCallback(() => {
    console.log("[usePcmStream] stopCaptureOnly()");

    sourceRef.current?.disconnect();
    processorRef.current?.disconnect();

    sourceRef.current = null;
    processorRef.current = null;

    // UIì—ì„œ ë…¹ìŒì¤‘ í‘œì‹œë§Œ ë„ê¸°
    setIsStreaming(false);
  }, []);

  // ì„œë²„ì—ì„œ ì˜¨ PCMì„ ì¬ìƒí•˜ëŠ” í—¬í¼
  const playPcmFromServer = useCallback(
    (arrayBuffer: ArrayBuffer) => {
      const audioContext = audioContextRef.current;
      if (!audioContext) {
        console.warn("AudioContext ì—†ìŒ â€“ ì•„ì§ start() ì•ˆ ëœ ìƒíƒœì¼ ìˆ˜ ìˆì–´ìš”");
        return;
      }

      // ì„œë²„ê°€ ë³´ë‚´ì¤€ ê±´ 16bit PCM(ëª¨ë…¸)ë¼ê³  ê°€ì •
      const pcm16 = new Int16Array(arrayBuffer);
      const numSamples = pcm16.length;

      const audioBuffer = audioContext.createBuffer(1, numSamples, SAMPLE_RATE);
      const channelData = audioBuffer.getChannelData(0);

      // Int16 -> Float32(-1.0 ~ 1.0)
      for (let i = 0; i < numSamples; i++) {
        channelData[i] = pcm16[i] / 0x8000;
      }

      const source = audioContext.createBufferSource();
      source.buffer = audioBuffer;
      source.connect(audioContext.destination);

      // âœ… ì¬ìƒ ì¤‘ ì¹´ìš´íŠ¸ ì¦ê°€
      playingCountRef.current += 1;

      source.onended = () => {
        playingCountRef.current -= 1;

        // âœ… END ë°›ì€ ìƒíƒœì´ê³  ë” ì¬ìƒí•  ì¡°ê°ì´ ì—†ìœ¼ë©´ ê·¸ë•Œ ìµœì¢… ì¢…ë£Œ
        if (endingRef.current && playingCountRef.current <= 0) {
          finalClose();
        }
      };

      source.start();
    },
    [finalClose]
  );

  // stop() - ìŒì„± ìŠ¤íŠ¸ë¦¼ â€œì™„ì „ ì¢…ë£Œâ€ (+ ë””ë²„ê·¸ WAV ìƒì„±)
  const stop = useCallback(() => {
    if (!isStreaming && !wsRef.current && !audioContextRef.current) return;
    if (isStoppingRef.current) return;
    isStoppingRef.current = true;

    console.log("[usePcmStream] stop() called");

    // ì˜¤ë””ì˜¤ ë…¸ë“œ ì—°ê²° í•´ì œ
    sourceRef.current?.disconnect();
    processorRef.current?.disconnect();
    sourceRef.current = null;
    processorRef.current = null;

    // ë””ë²„ê·¸ìš© WAV íŒŒì¼ ìƒì„± (ì›í•˜ë©´ ìœ ì§€)
    const recorded = recordedChunksRef.current;
    if (recorded.length > 0) {
      const totalSamples = recorded.reduce((sum, arr) => sum + arr.length, 0);
      const merged = new Int16Array(totalSamples);

      let offset = 0;
      for (const chunk of recorded) {
        merged.set(chunk, offset);
        offset += chunk.length;
      }

      const wavBuffer = encodeWav(merged, debugSampleRate);
      const blob = new Blob([wavBuffer], { type: "audio/wav" });
      const url = URL.createObjectURL(blob);
      setDebugAudioUrl(url);
    }

    // âœ… END ëŒ€ê¸° ìƒíƒœë„ ì´ˆê¸°í™”
    endingRef.current = false;
    playingCountRef.current = 0;

    // âœ… ì™„ì „ ì¢…ë£Œ
    finalClose();

    setIsStreaming(false);
    setIsWsOpen(false);
  }, [debugSampleRate, isStreaming]);

  // âœ… stopRefì— ìµœì‹  stop ì—°ê²°
  useEffect(() => {
    stopRef.current = stop;
  }, [stop]);

  // âœ… ìƒˆë¡œê³ ì¹¨/ë’¤ë¡œê°€ê¸°/íƒ­ë‹«ê¸° ë“± í˜ì´ì§€ ì´íƒˆ ì‹œ â€œì¦‰ì‹œ ì™„ì „ ì¢…ë£Œâ€
  useEffect(() => {
    const cleanup = () => {
      stopRef.current?.();
    };

    window.addEventListener("beforeunload", cleanup);
    window.addEventListener("pagehide", cleanup);

    const onVis = () => {
      if (document.visibilityState === "hidden") cleanup();
    };
    document.addEventListener("visibilitychange", onVis);

    return () => {
      window.removeEventListener("beforeunload", cleanup);
      window.removeEventListener("pagehide", cleanup);
      document.removeEventListener("visibilitychange", onVis);
    };
  }, []);

  // start() - ìŒì„± ìŠ¤íŠ¸ë¦¼ ì‹œì‘
  const start = useCallback(async () => {
    console.log("[usePcmStream] start() called");

    if (isStreaming) return;

    // startí•˜ë©´ stop ê°€ë“œ/END ìƒíƒœ ì´ˆê¸°í™”
    isStoppingRef.current = false;
    endingRef.current = false;
    playingCountRef.current = 0;

    // 0. WebSocket ì—°ê²°
    if (wsUrl) {
      try {
        const ws = new WebSocket(wsUrl);
        ws.binaryType = "arraybuffer";
        wsRef.current = ws;

        ws.onopen = () => {
          setIsWsOpen(true);
          console.log("[usePcmStream] WS OPEN");
        };

        ws.onmessage = (event) => {
            if (typeof event.data === "string") {
                const raw = event.data.trim().replace(/^"|"$/g, "");
                console.log("[WS] TEXT FROM SERVER:", raw);

                // 1) JSON ë©”íƒ€ ë©”ì‹œì§€ ìš°ì„  íŒŒì‹± ì‹œë„
                try {
                const obj = JSON.parse(raw);

                // âœ… ì§„ì§œ ì¢…ë£Œ íŠ¸ë¦¬ê±°: closeAfterSend === true
                if (obj?.closeAfterSend === true) {
                    console.log("[WS] closeAfterSend=true -> stopCaptureOnly(), wait TTS then close");
                    endingRef.current = true;

                    // ë§ˆì´í¬ ì†¡ì‹ ë§Œ ì¤‘ë‹¨ (TTS ìˆ˜ì‹ /ì¬ìƒì€ ê³„ì†)
                    stopCaptureOnly();

                    // ì´ë¯¸ ì¬ìƒ ì¤‘ì¸ ì¡°ê° ì—†ìœ¼ë©´ ì¦‰ì‹œ ì¢…ë£Œ
                    if (playingCountRef.current <= 0) finalClose();
                    return;
                }

                // í•„ìš”í•˜ë©´ ë‹¤ë¥¸ ë©”íƒ€ë„ ì—¬ê¸°ì„œ ì²˜ë¦¬
                // ex) obj.type === "STT_RESULT" ...
                return;
                } catch {
                // JSON ì•„ë‹ˆë©´ ê·¸ëƒ¥ í‰ë¬¸ í…ìŠ¤íŠ¸ë¡œ ì²˜ë¦¬
                }

                // 2) âœ… ENDëŠ” â€œì¢…ë£Œ íŠ¸ë¦¬ê±°â€ê°€ ì•„ë‹˜ (ê·¸ëƒ¥ ì•ˆë‚´/ìƒíƒœ í‘œì‹œìš©)
                if (raw === "END") {
                console.log("[WS] END received (NOT closing).");
                // TODO: í™”ë©´ì—ì„œ ë ˆì‹œí”¼ ëë‚¬ë‹¤ê³  í‘œì‹œë§Œ í•˜ê³  ì•„ë¬´ê²ƒë„ ëŠì§€ ë§ê¸°
                return;
                }

                // ê¸°íƒ€ í…ìŠ¤íŠ¸(STT ê²°ê³¼ ë“±)
                return;
            }

  // ë°”ì´ë„ˆë¦¬(TTS PCM)
  if (event.data instanceof ArrayBuffer) {
    console.log("[WS] BINARY FROM SERVER (TTS PCM):", event.data.byteLength);
    playPcmFromServer(event.data);
    return;
  }

  console.log("[WS] UNKNOWN MESSAGE TYPE", event.data);
};


        ws.onerror = (err) => {
          console.warn("WebSocket ì—°ê²° ì—ëŸ¬, ë…¹ìŒì€ ë¡œì»¬ì—ì„œë§Œ ì§„í–‰í•©ë‹ˆë‹¤.", err);
        };

        ws.onclose = () => {
          setIsWsOpen(false);
          console.log("[usePcmStream] WS CLOSED");
        };
      } catch (e) {
        console.warn("WebSocket ìƒì„± ì‹¤íŒ¨, ë…¹ìŒì€ ë¡œì»¬ì—ì„œë§Œ ì§„í–‰í•©ë‹ˆë‹¤.", e);
      }
    }

    // 1. ë§ˆì´í¬ ê¶Œí•œ ìš”ì²­
    const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
    console.log("[usePcmStream] mic stream acquired");

    // ì˜¤ë””ì˜¤ ì»¨í…ìŠ¤íŠ¸ ìƒì„±
    const audioContext = new AudioContext({ sampleRate: 16000 });
    audioContextRef.current = audioContext;

    setDebugSampleRate(audioContext.sampleRate);

    // WS ì—´ë ¤ìˆìœ¼ë©´ READY ë³´ëƒ„
    if (wsRef.current?.readyState === WebSocket.OPEN) {
      wsRef.current.send("READY");
      console.log("READY sent");
    }

    // ë§ˆì´í¬ ìŠ¤íŠ¸ë¦¼ì„ AudioContextì— ì—°ê²°
    const source = audioContext.createMediaStreamSource(stream);
    sourceRef.current = source;

    // PCM ë°ì´í„°ë¥¼ ì½œë°±ìœ¼ë¡œ ë°›ì„ Processor Node
    const processor = audioContext.createScriptProcessor(4096, 1, 1);
    processorRef.current = processor;

    // ë””ë²„ê·¸ ì •ë³´ ì´ˆê¸°í™”
    setChunkCount(0);
    setTotalBytes(0);
    recordedChunksRef.current = [];
    setDebugAudioUrl(null);

    processor.onaudioprocess = (e) => {
      const input = e.inputBuffer.getChannelData(0);
      const pcm16 = float32ToInt16(input);

      // WebSocketì´ ì‚´ì•„ ìˆìœ¼ë©´ ì„œë²„ì— ì „ì†¡
      if (wsRef.current) {
        if (wsRef.current.readyState === WebSocket.OPEN) {
          wsRef.current.send(pcm16.buffer);
          console.log("ğŸ“¤ sent chunk", pcm16.byteLength);
        } else {
          console.log("âš ï¸ ws not open, readyState =", wsRef.current.readyState);
        }
      }

      recordedChunksRef.current.push(pcm16);
      setChunkCount((c) => c + 1);
      setTotalBytes((b) => b + pcm16.byteLength);
    };

    source.connect(processor);
    processor.connect(audioContext.destination);

    setIsStreaming(true);
  }, [isStreaming, wsUrl, playPcmFromServer, stopCaptureOnly, finalClose]);

  return {
    start,
    stop, // ìˆ˜ë™ ì¢…ë£Œ(ì¦‰ì‹œ ì™„ì „ ì¢…ë£Œ)ìš©
    isStreaming,
    isWsOpen,
    chunkCount,
    totalBytes,
    debugAudioUrl,
  };
}

// Float32 ë°°ì—´(ë¸Œë¼ìš°ì € ê¸°ë³¸ ì˜¤ë””ì˜¤ í˜•ì‹) â†’ Int16 PCM ë³€í™˜
function float32ToInt16(float32Array: Float32Array): Int16Array {
  const int16Array = new Int16Array(float32Array.length);
  for (let i = 0; i < float32Array.length; i++) {
    const s = Math.max(-1, Math.min(1, float32Array[i]));
    int16Array[i] = s < 0 ? s * 0x8000 : s * 0x7fff;
  }
  return int16Array;
}

// pure PCM(Int16Array) â†’ WAV íŒŒì¼ë¡œ ë³€í™˜ (í—¤ë” ë¶™ì´ê¸°)
function encodeWav(samples: Int16Array, sampleRate: number): ArrayBuffer {
  const buffer = new ArrayBuffer(44 + samples.length * 2);
  const view = new DataView(buffer);

  const writeString = (offset: number, str: string) => {
    for (let i = 0; i < str.length; i++) {
      view.setUint8(offset + i, str.charCodeAt(i));
    }
  };

  const numChannels = 1;
  const bitsPerSample = 16;

  writeString(0, "RIFF");
  view.setUint32(4, 36 + samples.length * 2, true);
  writeString(8, "WAVE");
  writeString(12, "fmt ");
  view.setUint32(16, 16, true);
  view.setUint16(20, 1, true);
  view.setUint16(22, numChannels, true);
  view.setUint32(24, sampleRate, true);
  view.setUint32(28, (sampleRate * numChannels * bitsPerSample) / 8, true);
  view.setUint16(32, (numChannels * bitsPerSample) / 8, true);
  view.setUint16(34, bitsPerSample, true);
  writeString(36, "data");
  view.setUint32(40, samples.length * 2, true);

  let offset = 44;
  for (let i = 0; i < samples.length; i++, offset += 2) {
    view.setInt16(offset, samples[i], true);
  }

  return buffer;
}
