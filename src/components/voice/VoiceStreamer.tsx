// src/components/voice/VoiceStreamer.tsx
import { useEffect, useRef } from 'react'

type Props = {
  ws: WebSocket | null
  active: boolean // WS ì—°ê²° ì—¬ë¶€ ê°™ì€ ê±¸ ë„˜ê²¨ì£¼ë©´ ë¨
  sampleRate?: number // ê¸°ë³¸ 16k
}

function float32ToInt16(buffer: Float32Array): Int16Array {
  const l = buffer.length
  const result = new Int16Array(l)
  for (let i = 0; i < l; i++) {
    const s = Math.max(-1, Math.min(1, buffer[i]))
    result[i] = s < 0 ? s * 0x8000 : s * 0x7fff
  }
  return result
}

export function VoiceStreamer({ ws, active, sampleRate = 16000 }: Props) {
  const audioContextRef = useRef<AudioContext | null>(null)
  const sourceRef = useRef<MediaStreamAudioSourceNode | null>(null)
  const processorRef = useRef<ScriptProcessorNode | null>(null)
  const streamRef = useRef<MediaStream | null>(null)

  const stopMicStream = () => {
    processorRef.current?.disconnect()
    sourceRef.current?.disconnect()
    processorRef.current = null
    sourceRef.current = null

    audioContextRef.current?.close()
    audioContextRef.current = null

    if (streamRef.current) {
      streamRef.current.getTracks().forEach(t => t.stop())
      streamRef.current = null
    }
    console.log('ğŸ™ VoiceStreamer: ë§ˆì´í¬ ìŠ¤íŠ¸ë¦¬ë° ì¢…ë£Œ')
  }

  useEffect(() => {
    if (!active || !ws || ws.readyState !== WebSocket.OPEN) {
      // ë¹„í™œì„± ë˜ëŠ” WS ë¯¸ì—°ê²°ì´ë©´ ì •ë¦¬
      stopMicStream()
      return
    }

    let cancelled = false

    const startMicStream = async () => {
      try {
        console.log('ğŸ™ VoiceStreamer: ë§ˆì´í¬ ìŠ¤íŠ¸ë¦¬ë° ì‹œì‘ ì‹œë„')
        const stream = await navigator.mediaDevices.getUserMedia({ audio: true })
        if (cancelled) {
          // useEffect cleanup ì¤‘ì´ë©´ ë°”ë¡œ ì •ë¦¬
          stream.getTracks().forEach(t => t.stop())
          return
        }

        streamRef.current = stream

        const audioContext = new AudioContext({ sampleRate })
        audioContextRef.current = audioContext

        const source = audioContext.createMediaStreamSource(stream)
        sourceRef.current = source

        const processor = audioContext.createScriptProcessor(4096, 1, 1)
        processorRef.current = processor

        processor.onaudioprocess = e => {
          if (!ws || ws.readyState !== WebSocket.OPEN) return
          const input = e.inputBuffer.getChannelData(0)
          const pcm16 = float32ToInt16(input)
          ws.send(pcm16.buffer) // ğŸ”¥ ì‹¤ì‹œê°„ PCM ì „ì†¡
        }

        source.connect(processor)
        // processor.connect(audioContext.destination) // í•„ìš” ì—†ìœ¼ë©´ ì£¼ì„ ìœ ì§€

        console.log('ğŸ™ VoiceStreamer: ë§ˆì´í¬ ìŠ¤íŠ¸ë¦¬ë° ì‹œì‘ ì™„ë£Œ')
      } catch (err) {
        console.error('VoiceStreamer: ë§ˆì´í¬ ê¶Œí•œ ì‹¤íŒ¨', err)
        alert('ë§ˆì´í¬ ê¶Œí•œì„ í—ˆìš©í•´ ì£¼ì„¸ìš”.')
      }
    }

    startMicStream()

    return () => {
      cancelled = true
      stopMicStream()
    }
    // ws, active, sampleRate ë°”ë€” ë•Œë§ˆë‹¤ ë‹¤ì‹œ í‰ê°€
  }, [ws, active, sampleRate])

  // UI ì—†ëŠ” â€œë™ì‘ë§Œ í•˜ëŠ”â€ ì»´í¬ë„ŒíŠ¸ë¼ null ë¦¬í„´
  return null
}
